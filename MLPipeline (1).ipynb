{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa27b7-8edf-4710-901b-5c660a6cb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME: ANOOSHA IKRAM\n",
    "TASK-02: End-to-End ML Pipeline with Scikit-learn Pipeline API\n",
    "GOAL:Building a reusable and production-ready machine learning pipeline for predicting customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8baead9-0c41-42e7-a8d0-81da2a37cdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "print(data.shape)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40690dbb-d81e-4687-961b-2e966d21c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# 1. Load Dataset\n",
    "data = pd.read_csv(\"Telco-Customer-Churn.csv\")  # replace with your dataset path\n",
    "\n",
    "# Target variable\n",
    "y = data[\"Churn\"].apply(lambda x: 1 if x == \"Yes\" else 0)\n",
    "X = data.drop(columns=[\"Churn\", \"customerID\"])  # drop target + ID\n",
    "\n",
    "# 2. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 3. Preprocessing: numerical + categorical\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Define models with pipeline\n",
    "log_reg = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 5. Define hyperparameters for tuning\n",
    "param_grid = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression(max_iter=1000)],\n",
    "        'classifier__C': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [5, 10, None]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 6. GridSearchCV\n",
    "grid = GridSearchCV(Pipeline([(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]),\n",
    "                   param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "\n",
    "# 7. Evaluate on test set\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Export best pipeline\n",
    "joblib.dump(grid.best_estimator_, \"churn_pipeline.pkl\")\n",
    "print(\"Pipeline saved as churn_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb6931-35d5-4d1f-a427-771c88f9b47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
